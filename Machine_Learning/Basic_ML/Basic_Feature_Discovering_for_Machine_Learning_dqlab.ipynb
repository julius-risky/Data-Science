{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enginering\n",
    "Feature Engineering adalah proses dimana kita menerapkan pengetahuan yang kita punya untuk mendapatkan informasi yang lebih dari data yang kita punya. Contohnya dari KTP seseorang, anda sebenarnya dapat mendapatkan domisili pembuatan KTP, tanggal lahir, usia, dan jenis kelamin. Anda dapat menggolongkan orang-orang dengan kategori yang sama untuk membuat machine learning lebih mudah membedakan ciri orang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    #digunakan untuk menggabungkan dua dataset/dataframe dari 2 csv menjadi satu dataframe\n",
    "    #returns a concatenated df of training and test set\n",
    "    return pd.concat([train_data,test_data],sort=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "df_train = pd.read_csv('https://academy.dqlab.id/dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://academy.dqlab.id/dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train,df_test)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfs = [df_train, df_test]\n",
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penjelasan dari dataset\n",
    "\n",
    "   - PassengerId adalah id pada row, maka tidak ada pengaruh terhadap target yang dicari\n",
    "   - Survived adalah target yang akan diprediksi, nilai 0 = Not Survived dan nilai 1 = Survived\n",
    "\n",
    "   - Pclass (Passenger Class) adalah kategori level sosial ekonomi penumpang dengan nilai (1, 2 atau 3):\n",
    "   \n",
    "        1. = Upper Class\n",
    "        2. = Middle Class\n",
    "        3. = Lower Class\n",
    "\n",
    "   - Name, Sex dan Age merupakan data self-explanatory\n",
    "   - SibSp adalah jumlah saudara dari penumpang\n",
    "   - Parch adalah jumlah Orang Tua dan anak dari penumpang\n",
    "   - Ticket adalah jumlah tiket penumpang\n",
    "   - Fare adalah tarif yang di kenakan kepada penumpang\n",
    "   - Cabin adalah nomor kabin penumpang\n",
    "   - Embarked adalah pelabuhan pemberangkatan ada 3 pelabuhan (C, Q atau S): \n",
    "        C. = Cherbourg\n",
    "        Q. = Queenstown\n",
    "        S. = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['Survived'].shape))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value dan Contoh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info(memory_usage=False)\n",
    "print(df_train.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengetahui Korelasi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_corr = df_train.corr().abs()\n",
    "print(df_train_corr.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing data dari kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist():          \n",
    "        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "\n",
    "for df in dfs:\n",
    "    print('{}'.format(df.name))\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mencari nilai untuk missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_by_pclass_sex = df_all.groupby(['Sex','Pclass']).median()['Age']\n",
    "\n",
    "for pclass in range(1,4):\n",
    "    for sex in ['female','male']:\n",
    "        print('Median age of pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n",
    "    print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n",
    "    \n",
    "#filling the missing values in Age with the medians of Sex and Pclass groups\n",
    "df_all['Age']=df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengisi nilai kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values in Embarked with S\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "    \n",
    "med_fare = df_all.groupby(['Pclass','Parch','SibSp']).Fare.median()[3][0][0]\n",
    "# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))\n",
    "plt.subplots_adjust(right=1.5, top=1.25)\n",
    "\n",
    "for i, feature in enumerate(cat_features, 1):    \n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=feature, hue='Survived', data=df_train)\n",
    "    \n",
    "    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n",
    "    plt.ylabel('Passenger Count', size=20, labelpad=15)    \n",
    "    plt.tick_params(axis='x', labelsize=20)\n",
    "    plt.tick_params(axis='y', labelsize=20)\n",
    "    \n",
    "    plt.legend(['Not Survived', 'Survived'], loc='upper center', prop={'size': 18})\n",
    "    plt.title('Count of Survival in {} Feature'.format(feature), size=20, y=1.05)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exploring data Survived or not group by fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(22, 9))\n",
    "sns.countplot(x='Fare', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Fare', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=10)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Count of Survival in {} Feature'.format('Fare'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "adalah tentang membuat fitur baru dari fitur yang sudah ada.\n",
    "Dari sini kita akan membuat beberapa fitur baru yang bertujuan menaikkan akurasi dari model machine learning kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size'].value_counts().index, y=df_all['Family_Size'].value_counts().values, ax=axs[0][0])\n",
    "sns.countplot(x='Family_Size', hue='Survived', data=df_all, ax=axs[0][1])\n",
    "\n",
    "axs[0][0].set_title('Family Size Feature Value Counts', size=20, y=1.05)\n",
    "axs[0][1].set_title('Survival Counts in Family Size ', size=20, y=1.05)\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size_Grouped'].value_counts().index, y=df_all['Family_Size_Grouped'].value_counts().values, ax=axs[1][0])\n",
    "sns.countplot(x='Family_Size_Grouped', hue='Survived', data=df_all, ax=axs[1][1])\n",
    "\n",
    "axs[1][0].set_title('Family Size Feature Value Counts After Grouping', size=20, y=1.05)\n",
    "axs[1][1].set_title('Survival Counts in Family Size After Grouping', size=20, y=1.05)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i][1].legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 20})\n",
    "    for j in range(2):\n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "        axs[i][j].set_xlabel('')\n",
    "        axs[i][j].set_ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12, 9))\n",
    "sns.countplot(x='Ticket_Frequency', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Ticket Frequency', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Count of Survival in {} Feature'.format('Ticket Frequency'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "\n",
    "print(df_all['Title'].unique())\n",
    "\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1\n",
    "\n",
    "print(df_all['Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[0])\n",
    "\n",
    "axs[0].tick_params(axis='x', labelsize=10)\n",
    "axs[1].tick_params(axis='x', labelsize=15)\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='y', labelsize=15)\n",
    "\n",
    "axs[0].set_title('Title Feature Value Counts', size=20, y=1.05)\n",
    "\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[1])\n",
    "axs[1].set_title('Title Feature Value Counts After Grouping', size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "non_numeric_features = ['Embarked', 'Sex', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])\n",
    "        \n",
    "cat_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:5]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[5:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Cabin', 'Embarked', 'Survived', 'Name', 'PassengerId', 'Pclass', 'Sex', 'Ticket', 'Title']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data\n",
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitting model random forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_forest = RandomForestClassifier(criterion='gini', \n",
    "                                           n_estimators=1100,\n",
    "                                           max_depth=5,\n",
    "                                           min_samples_split=4,\n",
    "                                           min_samples_leaf=5,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=50)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "\n",
    "print(\"Scores:\\n\", scores)\n",
    "\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling tanpa feature enginering\n",
    "dengan menghapus column yg telah kita tambahkan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Cabin', 'Embarked', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n",
    "             'Name', 'PassengerId', 'Pclass', 'Sex', 'Ticket', 'Title',\n",
    "             'Family_Size_Grouped_1', 'Family_Size_Grouped_2', 'Family_Size_Grouped_3', 'Family_Size_Grouped_4',\n",
    "             'Ticket_Frequency', 'Title_1', 'Title_2', 'Title_3', 'Title_4', 'Is_Married']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "df_all.head()\n",
    "\n",
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
